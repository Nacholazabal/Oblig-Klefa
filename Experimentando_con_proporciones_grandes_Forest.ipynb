{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSxBxOYEf8Yv"
      },
      "source": [
        "# Proporciones altas de fondos en test - usando HOG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09xelfaFf8Yy"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G7Fxy31bf8Yy"
      },
      "outputs": [],
      "source": [
        "# Encadenar iterables\n",
        "from itertools import chain\n",
        "\n",
        "# Proporciona una barra de progreso rápida\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Interfaz para hacer gráficos y visualizaciones\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computación científica\n",
        "import numpy as np\n",
        "\n",
        "# Manipulación de datos\n",
        "import pandas as pd\n",
        "\n",
        "# Extraer parches (pequeños subconjuntos de imágenes) de imágenes\n",
        "from sklearn.feature_extraction.image import PatchExtractor\n",
        "\n",
        "# data: conjunto de datos de muestra y funciones de carga\n",
        "# color: convertir imágenes entre espacios de color\n",
        "# feature: funciones para identificar y extraer características de imágenes\n",
        "from skimage import data, color, feature\n",
        "\n",
        "# Cambiar el tamaño de una imagen\n",
        "from skimage.transform import resize, rescale\n",
        "\n",
        "# Descarga y carga en memoria un conjunto de datos de imágenes de caras de personas famosas\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "# Modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# La curva ROC\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Métricas varias\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07vNT-czf8Yz"
      },
      "source": [
        "## Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Adu4xGwZf8Y0"
      },
      "outputs": [],
      "source": [
        "# Función para extraer porciones de una imagen\n",
        "def extract_patches(img, N, scale=1.0, patch_size=(62,47), random_state=0):\n",
        "    # Calcula el tamaño del parche extraído basado en el factor de escala dado\n",
        "    H = img.shape[0]\n",
        "    W = img.shape[1]\n",
        "    H_patch = min(H , int(scale * patch_size[0]))\n",
        "    W_patch = min(W , int(scale * patch_size[1]))\n",
        "    extracted_patch_size = (H_patch, W_patch)\n",
        "\n",
        "    # Inicializa un objeto PatchExtractor con el tamaño de parche calculado,\n",
        "    # el número máximo de parches, y una semilla de estado aleatorio\n",
        "    extractor = PatchExtractor(patch_size=extracted_patch_size, max_patches=N, random_state=random_state)\n",
        "\n",
        "    # Extrae parches de la imagen dada\n",
        "    # img[np.newaxis] se utiliza la entrada de PatchExtractor es un conjunto de imágenes\n",
        "    patches = extractor.transform(img[np.newaxis])\n",
        "\n",
        "    # Si el factor de escala no es 1, redimensiona cada parche extraído\n",
        "    # al tamaño del parche original\n",
        "    if scale != 1:\n",
        "        patches = np.array([resize(patch, patch_size) for patch in patches])\n",
        "\n",
        "    # Devuelve la lista de parches extraídos (y posiblemente redimensionados)\n",
        "    return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a4QDF6r1f8Y0"
      },
      "outputs": [],
      "source": [
        "def non_max_suppression(indices, Ni, Nj, overlapThresh):\n",
        "    # Si no hay rectángulos, regresar una lista vacía\n",
        "    if len(indices) == 0:\n",
        "        return []\n",
        "\n",
        "    # Si las cajas son enteros, convertir a flotantes\n",
        "    if indices.dtype.kind == \"i\":\n",
        "        indices = indices.astype(\"float\")\n",
        "\n",
        "    # Inicializar la lista de índices seleccionados\n",
        "    pick = []\n",
        "\n",
        "    # Tomar las coordenadas de los cuadros\n",
        "    x1 = np.array([indices[i,0] for i in range(indices.shape[0])])\n",
        "    y1 = np.array([indices[i,1] for i in range(indices.shape[0])])\n",
        "    x2 = np.array([indices[i,0]+Ni for i in range(indices.shape[0])])\n",
        "    y2 = np.array([indices[i,1]+Nj for i in range(indices.shape[0])])\n",
        "\n",
        "    # Calcula el área de los cuadros y ordena los cuadros\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    # Mientras todavía hay índices en la lista de índices\n",
        "    while len(idxs) > 0:\n",
        "        # Toma el último índice de la lista y agrega el índice a la lista de seleccionados\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # Encontrar las coordenadas (x, y) más grandes para el inicio de la caja y las coordenadas (x, y) más pequeñas para el final de la caja\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # Calcula el ancho y alto de la caja\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # Calcula la proporción de superposición\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        # Elimina todos los índices del índice de lista que tienen una proporción de superposición mayor que el umbral proporcionado\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    # Devuelve solo las cajas seleccionadas\n",
        "    return indices[pick].astype(\"int\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lgq9eCsZf8Y0"
      },
      "outputs": [],
      "source": [
        "# Define una función para realizar una ventana deslizante (sliding window) sobre una imagen.\n",
        "def sliding_window(img,\n",
        "                   patch_size=(62,47),  # Define el tamaño del parche (patch) basado en el primer parche positivo por defecto\n",
        "                   istep=2,  # Paso de desplazamiento en la dirección i (verticalmente)\n",
        "                   jstep=2,  # Paso de desplazamiento en la dirección j (horizontalmente)\n",
        "                   scale=1.0):  # Factor de escala para ajustar el tamaño del parche\n",
        "\n",
        "    # Calcula las dimensiones Ni y Nj del parche ajustadas por el factor de escala.\n",
        "    Ni, Nj = (int(scale * s) for s in patch_size)\n",
        "\n",
        "    # Itera a lo largo de la imagen en la dirección i\n",
        "    for i in range(0, img.shape[0] - Ni, istep):\n",
        "        # Itera a lo largo de la imagen en la dirección j\n",
        "        for j in range(0, img.shape[1] - Ni, jstep):\n",
        "\n",
        "            # Extrae el parche de la imagen usando las coordenadas actuales i, j.\n",
        "            patch = img[i:i + Ni, j:j + Nj]\n",
        "\n",
        "            # Si el factor de escala es diferente de 1, redimensiona el parche al tamaño original del parche.\n",
        "            if scale != 1:\n",
        "                patch = resize(patch, patch_size)\n",
        "\n",
        "            # Usa yield para devolver las coordenadas actuales y el parche.\n",
        "            # Esto convierte la función en un generador.\n",
        "            yield (i, j), patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uT4nHUpQf8Y0"
      },
      "outputs": [],
      "source": [
        "# Función que devuelve el número de detecciones brutas y procesadas para diversas escalas\n",
        "# Esta función asume conocidos model, size y los parámetros de las HOG\n",
        "def detections_by_scale(test_image, test_scales, step, thresholds=[0.5]):\n",
        "    raw_detections = []\n",
        "    detections = []\n",
        "\n",
        "    for scale in tqdm(test_scales):\n",
        "        raw_detections_scale = []\n",
        "        detections_scale = []\n",
        "\n",
        "        # Ventana deslizante\n",
        "        indices, patches = zip(*sliding_window(test_image, scale=scale, istep=step, jstep=step))\n",
        "\n",
        "        # Calcula las características HOG para cada parche y las almacena en un array.\n",
        "        patches_hog = np.array([feature.hog(patch,\n",
        "                                            orientations=orientations,\n",
        "                                            pixels_per_cell=pixels_per_cell,\n",
        "                                            cells_per_block=cells_per_block) for patch in patches])\n",
        "        # Predicción\n",
        "        for thr in thresholds:\n",
        "            labels = (model.predict_proba(patches_hog)[:,1]>=thr).astype(int)\n",
        "            raw_detections_scale.append(labels.sum())\n",
        "            Ni, Nj = (int(scale*s) for s in size)\n",
        "            indices = np.array(indices)\n",
        "            detecciones = indices[labels == 1]\n",
        "            detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)\n",
        "            detections_scale.append(len(detecciones))\n",
        "\n",
        "        # Actualizamos las listas\n",
        "        raw_detections.append(raw_detections_scale)\n",
        "        detections.append(detections_scale)\n",
        "\n",
        "    return np.array(raw_detections), np.array(detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PmDI3bXif8Y1"
      },
      "outputs": [],
      "source": [
        "# True Positive Rate\n",
        "def tpr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  tpr = cm[1,1]/(cm[1,1]+cm[1,0])\n",
        "  return tpr\n",
        "\n",
        "# False Positive Rate\n",
        "def fpr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  fpr = cm[0,1]/(cm[0,0]+cm[0,1])\n",
        "  return fpr\n",
        "\n",
        "# True Negative Rate\n",
        "def tnr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  tnr = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "  return tnr\n",
        "\n",
        "# True Negative Rate\n",
        "def fnr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred,)\n",
        "  fnr = cm[1,0]/(cm[1,0]+cm[1,1])\n",
        "  return fnr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YERMJIvGf8Y1"
      },
      "source": [
        "## Dataset de rostros (LFW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AUe4YOGff8Y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e252b8ea-4c67-4314-c073-568528dd5478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13233, 62, 47)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Cargamos el dataset\n",
        "faces = fetch_lfw_people()\n",
        "positive_patches = faces.images\n",
        "positive_patches.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GlO84clVf8Y2"
      },
      "outputs": [],
      "source": [
        "# Dividimos en train y test\n",
        "positive_patches_train, positive_patches_test = train_test_split(\n",
        "    positive_patches,\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q-kdkcXFf8Y2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b55e086-e1f4-450a-ae01-145ed678ab60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape train:  (11909, 62, 47)\n",
            "Shape test:  (1324, 62, 47)\n"
          ]
        }
      ],
      "source": [
        "print('Shape train: ',positive_patches_train.shape)\n",
        "print('Shape test: ',positive_patches_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRrxvFmKf8Y3"
      },
      "source": [
        "## Dataset de fondos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kIeHvTjHf8Y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e808b6b-db11-4440-c96d-1a88823c3e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ],
      "source": [
        "# Tomamos algunas imágenes de sklearn\n",
        "imgs = ['camera',\n",
        "        'text',\n",
        "        'coins',\n",
        "        'moon',\n",
        "        'page',\n",
        "        'clock',\n",
        "        'immunohistochemistry',\n",
        "        'chelsea',\n",
        "        'coffee',\n",
        "        'hubble_deep_field'\n",
        "        ]\n",
        "\n",
        "backgrounds = []\n",
        "for name in imgs:\n",
        "    img = getattr(data, name)()\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:  # Chequeamos si la imagen es RGB\n",
        "        img = color.rgb2gray(img)\n",
        "    backgrounds.append(img)\n",
        "\n",
        "# Imagenes caseras adicionales\n",
        "for i in range(31):\n",
        "    filename = str(i)+'.jpg'\n",
        "    img = plt.imread(filename)\n",
        "    img = color.rgb2gray(img)\n",
        "    backgrounds.append(img)\n",
        "\n",
        "print(len(backgrounds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg_c20fPf8Y3"
      },
      "source": [
        "## Definimos el modelo, los datos y las HOG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uRToZdf7f8Y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045bba26-dda2-471b-cb38-9a6c47de9d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(max_depth=5)_R_1_S_[0.5, 1, 2, 4, 8]_PTrain_10_PTest_100_O_9_C_(8, 8)_B_(3, 3)\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth = 5)\n",
        "\n",
        "# Resolución de los rostros\n",
        "resolution = 1\n",
        "\n",
        "# Fondos\n",
        "scales = [0.5,1,2,4,8]\n",
        "proportion_train = 10\n",
        "proportion_test = 100\n",
        "num_patches_train = int((proportion_train * len(positive_patches_train))/(len(scales) * len(backgrounds)))\n",
        "num_patches_test = int((proportion_test * len(positive_patches_test))/(len(scales) * len(backgrounds)))\n",
        "\n",
        "# HOG\n",
        "orientations = 9\n",
        "pixels_per_cell = (8, 8)\n",
        "cells_per_block = (3, 3)\n",
        "\n",
        "# Nombre del experimento\n",
        "model_name = str(model)\n",
        "experiment_name = model_name\n",
        "experiment_name += '_R_' + str(resolution)\n",
        "experiment_name += '_S_' + str(scales)\n",
        "experiment_name += '_PTrain_' + str(proportion_train)\n",
        "experiment_name += '_PTest_' + str(proportion_test)\n",
        "experiment_name += '_O_' + str(orientations)\n",
        "experiment_name += '_C_' + str(pixels_per_cell)\n",
        "experiment_name += '_B_' + str(cells_per_block)\n",
        "\n",
        "print(experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9RXmMZV0f8Y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30390e65-8366-4f9f-aaa7-332757033528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11909/11909 [00:16<00:00, 728.29it/s] \n",
            "100%|██████████| 1324/1324 [00:01<00:00, 961.49it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de los rostros:  (62, 47)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Tamaño de las imágenes de rostros\n",
        "\n",
        "# Train\n",
        "positive_patches_train = np.array(\n",
        "    [rescale(positive_patches_train[i], resolution)\n",
        "    for i in tqdm(range(len(positive_patches_train)))]\n",
        "    )\n",
        "\n",
        "# Test\n",
        "positive_patches_test = np.array(\n",
        "    [rescale(positive_patches_test[i], resolution)\n",
        "    for i in tqdm(range(len(positive_patches_test)))]\n",
        "    )\n",
        "\n",
        "size = positive_patches_train[0].shape\n",
        "print('Tamaño de los rostros: ',size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeK9gCt_f8Y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3487bd-86fc-4285-87ef-580ad0c2a7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes train:   2%|▏         | 1/41 [00:16<11:07, 16.69s/it]"
          ]
        }
      ],
      "source": [
        "# Extraemos las imágenes de fondo\n",
        "\n",
        "# Train\n",
        "negative_patches_train = np.vstack(\n",
        "    [extract_patches(im, num_patches_train, scale, random_state=42)\n",
        "    for im in tqdm(backgrounds, desc='Procesando imágenes train')\n",
        "    for scale in scales]\n",
        "    )\n",
        "\n",
        "# Test\n",
        "negative_patches_test = np.vstack(\n",
        "    [extract_patches(im, num_patches_test, scale, random_state=0)\n",
        "    for im in tqdm(backgrounds, desc='Procesando imágenes test')\n",
        "    for scale in scales]\n",
        "    )\n",
        "\n",
        "print('Shape train: ',negative_patches_train.shape)\n",
        "print('Shape test: ',negative_patches_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmn32oZSf8Y4"
      },
      "outputs": [],
      "source": [
        "# Armamos la matriz de features y el vector de etiquetas\n",
        "\n",
        "# Train\n",
        "X_train = np.array(\n",
        "    [feature.hog(image=im,\n",
        "                 orientations=orientations,\n",
        "                 pixels_per_cell=pixels_per_cell,\n",
        "                 cells_per_block=cells_per_block)\n",
        "    for im in tqdm(chain(positive_patches_train, negative_patches_train))]\n",
        "    )\n",
        "y_train = np.zeros(X_train.shape[0])\n",
        "y_train[:positive_patches_train.shape[0]] = 1\n",
        "\n",
        "# Test\n",
        "X_test = np.array(\n",
        "    [feature.hog(image=im,\n",
        "                 orientations=orientations,\n",
        "                 pixels_per_cell=pixels_per_cell,\n",
        "                 cells_per_block=cells_per_block)\n",
        "    for im in tqdm(chain(positive_patches_test, negative_patches_test))]\n",
        "    )\n",
        "y_test = np.zeros(X_test.shape[0])\n",
        "y_test[:positive_patches_test.shape[0]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77uVVGH8f8Y5"
      },
      "outputs": [],
      "source": [
        "print('Shape X_train: ', X_train.shape)\n",
        "print('Shape y_train: ', y_train.shape)\n",
        "print('Shape X_test: ', X_test.shape)\n",
        "print('Shape y_test: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cdOv_BMf8Y5"
      },
      "source": [
        "## Entrenamiento y evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRWrPVapf8Y5"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTME5Ftrf8Y5"
      },
      "outputs": [],
      "source": [
        "# Predicciones\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRMbkkapf8Y5"
      },
      "outputs": [],
      "source": [
        "# Métrcias\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "b_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test,y_pred,average='macro')\n",
        "rec = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "tpr = tpr_scorer(model, X_test, y_test)\n",
        "fpr = fpr_scorer(model, X_test, y_test)\n",
        "tnr = tnr_scorer(model, X_test, y_test)\n",
        "fnr = fnr_scorer(model, X_test, y_test)\n",
        "\n",
        "# Guardamos en un dataframe\n",
        "results = pd.Series(\n",
        "    data={\n",
        "        'ACCURACY': acc,\n",
        "        'PRECISION': prec,\n",
        "        'RECALL': rec,\n",
        "        'F1': f1,\n",
        "        'B_ACCURACY': b_acc,\n",
        "        'AUC': auc,\n",
        "        'TPR': tpr,\n",
        "        'FPR': fpr,\n",
        "        'TNR': tnr,\n",
        "        'FNR': fnr\n",
        "    }\n",
        ")\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9_iywM1f8Y5"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,y_pred, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BC7qrYZf8Y6"
      },
      "outputs": [],
      "source": [
        "# Curva ROC y umbral óptimo\n",
        "fig, ax = plt.subplots(1,2,figsize=(8, 8))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "index = np.argmax(gmean)\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "ax[0].step(\n",
        "    fpr,\n",
        "    tpr,\n",
        "    lw=1,\n",
        "    alpha=1,\n",
        ")\n",
        "\n",
        "ax[0].plot(\n",
        "    fprOpt,\n",
        "    tprOpt,\n",
        "    marker = 'o'\n",
        ")\n",
        "\n",
        "ax[0].set(\n",
        "    xlim=[-0.05, 1.05],\n",
        "    ylim=[-0.05, 1.05],\n",
        "    xlabel=\"False Positive Rate\",\n",
        "    ylabel=\"True Positive Rate\",\n",
        "    title=f\"Curva ROC\",\n",
        ")\n",
        "ax[0].axis(\"square\")\n",
        "\n",
        "ax[1].set_aspect('equal')\n",
        "ax[1].set_xlim([-0.05, 0.1])\n",
        "ax[1].set_xbound(lower=-0.05, upper=0.1)\n",
        "ax[1].set_ylim([0.85,1])\n",
        "ax[1].set_ybound(lower=0.85, upper=1.0)\n",
        "\n",
        "ax[1].step(\n",
        "    fpr,\n",
        "    tpr,\n",
        "    lw=1,\n",
        "    alpha=1,\n",
        ")\n",
        "\n",
        "ax[1].plot(\n",
        "    fprOpt,\n",
        "    tprOpt,\n",
        "    marker = 'o'\n",
        ")\n",
        "\n",
        "ax[1].set(\n",
        "    xlabel=\"False Positive Rate\",\n",
        "    ylabel=\"True Positive Rate\",\n",
        "    title=f\"Zoom\",\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Umbral óptimo: {thresholdOpt}')\n",
        "print(f'FPR: {fprOpt}, TPR: {tprOpt}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFfMkhM7f8Y6"
      },
      "outputs": [],
      "source": [
        "# Otra forma de calcular un umbral adecuado\n",
        "indx = np.argmax(tpr>=0.90)\n",
        "thresholdAde = thresholds[indx]\n",
        "print('Umbral adecuado: ', thresholdAde)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbLBKNI4f8Y6"
      },
      "source": [
        "## Test en la imagen del astronauta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAmdQSZYf8Y6"
      },
      "outputs": [],
      "source": [
        "# Imagen de prueba\n",
        "test_image = data.astronaut()\n",
        "test_image = color.rgb2gray(test_image)\n",
        "test_image = rescale(test_image, 0.5)\n",
        "test_image = test_image[:160, 40:180]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCYKB-5pf8Y6"
      },
      "outputs": [],
      "source": [
        "# Visualizamos la imagen\n",
        "# Buscamos la escala de los rostros\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(test_image, cmap='gray')\n",
        "\n",
        "true_scale = 1\n",
        "Ni, Nj = (int(true_scale * s) for s in size)\n",
        "\n",
        "ax.add_patch(plt.Rectangle((0, 0), Nj, Ni, edgecolor='red', alpha=1, lw=1, facecolor='none'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N91iR4tPf8Y6"
      },
      "outputs": [],
      "source": [
        "# Utiliza la función de ventana deslizante en una imagen de prueba.\n",
        "# zip(*...) toma las tuplas generadas y las descompone en índices y parches.\n",
        "indices, patches = zip(*sliding_window(test_image, scale=1))\n",
        "\n",
        "# Calcula las características HOG para cada parche y las almacena en un array.\n",
        "patches_hog = np.array([feature.hog(patch,\n",
        "                                    orientations=orientations,\n",
        "                                    pixels_per_cell=pixels_per_cell,\n",
        "                                    cells_per_block=cells_per_block) for patch in patches])\n",
        "\n",
        "# Muestra la forma del array de características HOG.\n",
        "patches_hog.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZuDnnSQf8Y7"
      },
      "source": [
        "### Desempeño según umbrales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJmXDAuzf8Y7"
      },
      "outputs": [],
      "source": [
        "# Predicción\n",
        "\n",
        "# Umbral default\n",
        "labels_default = model.predict(patches_hog).astype(int)\n",
        "\n",
        "# Umbral óptimo\n",
        "labels_optimo = (model.predict_proba(patches_hog)[:,1]>=thresholdOpt).astype(int)\n",
        "\n",
        "# Umbral adecuado\n",
        "labels_adecuado = (model.predict_proba(patches_hog)[:,1]>=thresholdAde).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riSwEuwCf8Y7"
      },
      "outputs": [],
      "source": [
        "Ni, Nj = (int(true_scale*s) for s in size)\n",
        "indices = np.array(indices)\n",
        "\n",
        "# Umbral default\n",
        "detecciones_default = indices[labels_default == 1]\n",
        "detecciones_default = non_max_suppression(np.array(detecciones_default),Ni,Nj, 0.3)\n",
        "\n",
        "# Umbral optimo\n",
        "detecciones_optimo = indices[labels_optimo == 1]\n",
        "detecciones_optimo = non_max_suppression(np.array(detecciones_optimo),Ni,Nj, 0.3)\n",
        "\n",
        "# Umbral adecuado\n",
        "detecciones_adecuado = indices[labels_adecuado == 1]\n",
        "detecciones_adecuado = non_max_suppression(np.array(detecciones_adecuado),Ni,Nj, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL9D_fSHf8Y7"
      },
      "outputs": [],
      "source": [
        "# Visualizamos las detecciones\n",
        "fig, ax = plt.subplots(1,3, figsize=(8,4))\n",
        "\n",
        "# Umbral default\n",
        "ax[0].imshow(test_image, cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "for i, j in detecciones_default:\n",
        "    ax[0].add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',alpha=1, lw=1, facecolor='none'))\n",
        "\n",
        "ax[0].set_title('Default')\n",
        "\n",
        "# Umbral óptimo\n",
        "ax[1].imshow(test_image, cmap='gray')\n",
        "ax[1].axis('off')\n",
        "\n",
        "for i, j in detecciones_optimo:\n",
        "    ax[1].add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',alpha=1, lw=1, facecolor='none'))\n",
        "\n",
        "ax[1].set_title('Óptimo')\n",
        "\n",
        "# Umbral adecuado\n",
        "ax[2].imshow(test_image, cmap='gray')\n",
        "ax[2].axis('off')\n",
        "\n",
        "for i, j in detecciones_adecuado:\n",
        "    ax[2].add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',alpha=1, lw=1, facecolor='none'))\n",
        "\n",
        "ax[2].set_title('Adecuado')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGGLio4if8Y7"
      },
      "source": [
        "### Desempeño en varias escalas según umbral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fMd7EWif8Y8"
      },
      "outputs": [],
      "source": [
        "# Escalas a testear\n",
        "test_scales = np.linspace(0.125, 2, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwnPH8yyf8Y8"
      },
      "outputs": [],
      "source": [
        "raw_detections, detections = detections_by_scale(\n",
        "    test_image,\n",
        "    test_scales,\n",
        "    step=2,\n",
        "    thresholds=[0.5, thresholdOpt, thresholdAde]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R6BwHCPf8ZA"
      },
      "outputs": [],
      "source": [
        "number_faces = 1\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "\n",
        "ax[0].set_title('Bruto')\n",
        "ax[0].axvline(x=true_scale, ls = '--', color='red')\n",
        "ax[0].step(test_scales, raw_detections[:,0], label = 'Default')\n",
        "ax[0].step(test_scales, raw_detections[:,1], label = 'Óptimo')\n",
        "ax[0].step(test_scales, raw_detections[:,2], label = 'Adecuado')\n",
        "ax[0].grid(True)\n",
        "ax[0].set_xlabel('Escalas')\n",
        "ax[0].set_ylabel('Detecciones')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].set_title('Procesado')\n",
        "ax[1].axvline(x=true_scale, ls = '--', color='red')\n",
        "ax[1].axhline(y=number_faces, ls = '--', color='red')\n",
        "ax[1].step(test_scales, detections[:,0], label = 'Default')\n",
        "ax[1].step(test_scales, detections[:,1], label = 'Óptimo')\n",
        "ax[1].step(test_scales, detections[:,2], label = 'Adecuado')\n",
        "ax[1].grid(True)\n",
        "ax[1].set_xlabel('Escalas')\n",
        "ax[1].set_ylabel('Detecciones')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}